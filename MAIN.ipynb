{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CarDekho dataset into a Pandas dataframe\n",
    "df = pd.read_csv('Car details v3.csv')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(['Car_Name', 'Seller_Type'], axis=1)\n",
    "\n",
    "# Convert categorical variables into numerical ones using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Fuel_Type', 'Transmission'])\n",
    "\n",
    "# Convert year of manufacture into age of the car\n",
    "current_year = 2023\n",
    "df['Age'] = current_year - df['Year']\n",
    "df = df.drop(['Year'], axis=1)\n",
    "\n",
    "# Normalize the mileage and engine displacement features\n",
    "df['Mileage'] = (df['Mileage'] - df['Mileage'].mean()) / df['Mileage'].std()\n",
    "df['Engine'] = (df['Engine'] - df['Engine'].mean()) / df['Engine'].std()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['Selling_Price'], axis=1)\n",
    "y = df['Selling_Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Import the determined.ai library and create a Trial\n",
    "import determined as det\n",
    "from determined.experimental import Determined\n",
    "\n",
    "class MyTrial(det.Trial):\n",
    "    def build_model(self):\n",
    "        # Define the input layer\n",
    "        input_layer = det.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "        # Define the dense layers\n",
    "        dense_layer1 = det.keras.layers.Dense(units=64, activation='relu')(input_layer)\n",
    "        dense_layer2 = det.keras.layers.Dense(units=32, activation='relu')(dense_layer1)\n",
    "\n",
    "        # Define the output layer\n",
    "        output_layer = det.keras.layers.Dense(units=1)(dense_layer2)\n",
    "\n",
    "        # Create the model\n",
    "        model = det.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=det.keras.optimizers.Adam(learning_rate=self.context.get_hparam('learning_rate')),\n",
    "                      loss='mean_squared_error')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_training_data_loader(self):\n",
    "        return det.keras.DataLoader(X_train, y_train, batch_size=self.context.get_per_slot_batch_size())\n",
    "\n",
    "    def build_validation_data_loader(self):\n",
    "        return det.keras.DataLoader(X_test, y_test, batch_size=self.context.get_per_slot_batch_size())\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "hyperparameters = det.ExperimentHyperparameters(\n",
    "    hyperparameter_defaults={\n",
    "        'learning_rate': det.Constant(value=0.001),\n",
    "        'batch_size': det.Constant(value=64)\n",
    "    })\n",
    "\n",
    "# Define the experiment configuration\n",
    "config = {\n",
    "    'description': 'CarDekho price prediction',\n",
    "    'data': {\n",
    "        'train': X_train,\n",
    "        'val': X_test\n",
    "    },\n",
    "    'hyperparameters': hyperparameters,\n",
    "    'searcher': 'single',\n",
    "    'scheduler': det.schedulers.SingleStepLRScheduler(\n",
    "        step_size=20, gamma=0.1\n",
    "    ),\n",
    "    'model': det.Model(\n",
    "        model_def=MyTrial,\n",
    "        checkpoint_policy=det.CheckpointPolicy(\n",
    "            frequency=det.IntervalUnit.EPOCH, \n",
    "            interval=1\n",
    "        ),\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Start the experiment\n",
    "experiment_id = Determined().create_experiment(config=config)\n",
    "\n",
    "# Wait for the experiment to complete\n",
    "trial = Determined().get_experiment(experiment_id).top_trial()\n",
    "while trial.state != det.TrialState.COMPLETED:\n",
    "    trial = Determined().get_trial(trial_id=trial.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture\n",
    "model_def = \"\"\"\n",
    "    model:\n",
    "        type: feedforward\n",
    "        module:\n",
    "            type: torch\n",
    "            path: torch_nn.py\n",
    "            args:\n",
    "                hidden_size: 256\n",
    "                num_layers: 2\n",
    "                dropout: 0.1\n",
    "                activation: relu\n",
    "        input_ports:\n",
    "            features:\n",
    "                type: typed_csv\n",
    "                shape: !tuple [null, 7]\n",
    "        output_ports:\n",
    "            price:\n",
    "                type: float\n",
    "\"\"\"\n",
    "\n",
    "# Define the experiment configuration\n",
    "config = {\n",
    "    \"hyperparameters\": {\n",
    "        \"global_batch_size\": 64,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"num_epochs\": 50,\n",
    "        \"patience\": 3\n",
    "    },\n",
    "    \"searcher\": {\n",
    "        \"name\": \"single\",\n",
    "        \"metric\": \"val_loss\",\n",
    "        \"max_steps\": 50\n",
    "    },\n",
    "    \"scheduling_unit\": \"epoch\",\n",
    "    \"min_checkpoint_period\": \"00:01:00\",\n",
    "    \"min_validation_period\": \"00:01:00\",\n",
    "    \"data_layer\": {\n",
    "        \"name\": \"torch\",\n",
    "        \"args\": {\n",
    "            \"train_data\": {\n",
    "                \"type\": \"numpy\",\n",
    "                \"x\": X_train,\n",
    "                \"y\": y_train\n",
    "            },\n",
    "            \"val_data\": {\n",
    "                \"type\": \"numpy\",\n",
    "                \"x\": X_test,\n",
    "                \"y\": y_test\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"torch_feedforward\",\n",
    "        \"definition\": model_def\n",
    "    },\n",
    "    \"optimization\": {\n",
    "        \"name\": \"adam\",\n",
    "        \"args\": {}\n",
    "    },\n",
    "    \"execution\": {\n",
    "        \"num_training_units\": \"epoch\",\n",
    "        \"gpu\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an experiment in Determined\n",
    "experiment = determinedsys.create_experiment(config)\n",
    "\n",
    "# Train the model\n",
    "for i in range(config[\"searcher\"][\"max_steps\"]):\n",
    "    trial = experiment.get_trial()\n",
    "    model = trial.get_model()\n",
    "    model.fit(trial.get_batch_size(\"global_batch_size\"), trial.get_data_layer())\n",
    "    experiment.trial_close(trial, {\"val_loss\": model.evaluate(trial.get_data_layer())})\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_checkpoint = experiment.top_checkpoint()\n",
    "best_model = experiment.get_model_from_checkpoint(best_checkpoint)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_loss = best_model.evaluate(determined.TorchData(context=experiment.d.context, data=(X_test_scaled, y_test)))\n",
    "print(f\"Test loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import determined as det\n",
    "import determined.keras as detk\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('car_data.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "# One-hot encode the categorical features\n",
    "X = pd.get_dummies(pd.DataFrame(X, columns=['Car_Name', 'Fuel_Type', 'Seller_Type', 'Transmission']))\n",
    "X = X.values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model(hparams):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(hparams.get('hidden_size', 128), activation='relu'),\n",
    "        tf.keras.layers.Dropout(hparams.get('dropout', 0.2)),\n",
    "        tf.keras.layers.Dense(hparams.get('hidden_size', 128), activation='relu'),\n",
    "        tf.keras.layers.Dropout(hparams.get('dropout', 0.2)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hparams.get('learning_rate', 0.001)),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Define the experiment configuration\n",
    "config = {\n",
    "    'hyperparameters': {\n",
    "        'hidden_size': det.ConfigRange(128, 512, 128),\n",
    "        'dropout': det.ConfigRange(0.1, 0.5, 0.1),\n",
    "        'learning_rate': det.LogConfigRange(1e-4, 1e-2)\n",
    "    },\n",
    "    'searcher': {\n",
    "        'name': 'single',\n",
    "        'max_steps': 50,\n",
    "        'max_trials': 3\n",
    "    },\n",
    "    'data': {\n",
    "        'train': {\n",
    "            'x': X_train,\n",
    "            'y': y_train\n",
    "        },\n",
    "        'validation': {\n",
    "            'x': X_test,\n",
    "            'y': y_test\n",
    "        }\n",
    "    },\n",
    "    'model': {\n",
    "        'model_class': build_model,\n",
    "        'fit': {\n",
    "            'epochs': 50,\n",
    "            'batch_size': det.TrialContext(hparams='batch_size')\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a Determined experiment\n",
    "experiment_config = det.ExperimentConfig(\n",
    "    experiment_name='car_price_prediction',\n",
    "    description='Predict the price of a used car based on its features',\n",
    "    hyperparameters=config['hyperparameters'],\n",
    "    searcher=config['searcher'],\n",
    "    data=config['data'],\n",
    "    model=config['model']\n",
    ")\n",
    "experiment = det.create_experiment(experiment_config)\n",
    "\n",
    "# Train the model\n",
    "@det.keras.wrappers.training_loop\n",
    "def train(model, context):\n",
    "    model.fit(context.trial.train_dataset, epochs=context.get_hparam('fit.epochs'),\n",
    "              steps_per_epoch=context.get_per_slot_batch_size())\n",
    "\n",
    "train()\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_checkpoint = experiment.top_checkpoint()\n",
    "model = experiment.get_model_from_checkpoint(best_checkpoint)\n",
    "test_loss, test_mae = model.evaluate(x=X_test, y=y_test)\n",
    "print(f'Test loss: {test_loss:.2f}, Test MAE: {test_mae:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "car_data = pd.read_csv('car_data.csv')\n",
    "\n",
    "# Drop the name column\n",
    "car_data.drop('name', axis=1, inplace=True)\n",
    "\n",
    "# Convert the fuel type column to binary\n",
    "car_data['fuel_type'] = pd.get_dummies(car_data['fuel_type'], drop_first=True)\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "car_data = pd.get_dummies(car_data, columns=['seller_type', 'transmission', 'owner'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = car_data.drop('selling_price', axis=1)\n",
    "y = car_data['selling_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the model\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=100)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print('R^2 Score:', r2_score(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "model.save('car_price_prediction_model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
